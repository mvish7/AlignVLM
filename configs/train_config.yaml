# Model Configuration
model:
  model_id: "HuggingFaceTB/SmolVLM2-500M-Video-Instruct"
  resume_from_ckpt: true
  num_transformer_layers: 34
  lora_adapter_path: "/media/vishal/workspace/projects/gemma3_4b/align_vlm/checkpoints/pixmo_100k"

# Dataset Configuration
dataset:
  path: "/media/vishal/datasets/ln/metadata/"  # local dir path, to be used with load_from_disk
  id: ""  # HF dataset_id, to be used with load_dataset
  test_size: 0.1
  seed: 42

# LoRA Configuration
lora:
  lora_alpha: 64
  lora_dropout: 0.1
  r: 64
  use_rslora: true
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Configuration
training:
  output_dir: "/media/vishal/workspace/projects/gemma3_4b/align_vlm/checkpoints/localized_narratives_200k"
  num_train_epochs: 1
  optim: "adamw_torch_fused"
  logging_steps: 200
  save_strategy: "steps"
  save_steps: 2600
  learning_rate: 1e-4
  bf16: true
  report_to: "tensorboard"
  eval_strategy: "epoch"
  eval_accumulation_steps: 5
  warmup_steps: 70
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  weight_decay: 0.01
  use_cpu: false
  dataloader_num_workers: 6
  dataloader_pin_memory: true
  torch_empty_cache_steps: 20
  dataset_kwargs:
    skip_prepare_dataset: true 